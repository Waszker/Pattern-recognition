\relax 
\@writefile{toc}{\contentsline {title}{Regression Models for Classification \unskip \ \ignorespaces with Foreign Patterns Rejection}{1}}
\@writefile{toc}{\authcount {3}}
\@writefile{toc}{\contentsline {author}{Wladyslaw Homenda$^{1}$ \and Agnieszka Jastrzebska$^1$ \and Piotr Waszkiewicz$^{1}$ }{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\newlabel{sec:Introduction}{{1}{1}}
\citation{Grubbs1950,Tukey1977}
\citation{BreunigKriegelNgSander1999,KnorrNg1999}
\citation{PimentelCliftonTarassenko2014}
\citation{Kapoor2010,KimLee2006}
\citation{Paalanen2006,Song2007}
\citation{Chawla2006,Ghoting2008}
\citation{He2003,Sun2004}
\@writefile{toc}{\contentsline {section}{\numberline {2}Literature Review}{2}}
\newlabel{sec:Literature Review}{{2}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Preliminaries}{3}}
\newlabel{sec:preliminaries}{{3}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}The Task of Classification with Rejection}{3}}
\newlabel{sec:Known algorithms}{{3.1}{3}}
\citation{CortesVapnik1995}
\citation{Breiman2001}
\citation{Altman1992}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Support Vector Machines}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Random Forest}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}k-Nearest Neighbors}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Regression}{5}}
\newlabel{eq:regression}{{1}{5}}
\@writefile{toc}{\contentsline {paragraph}{Linear regression}{5}}
\newlabel{eq:lineraregression}{{2}{5}}
\@writefile{toc}{\contentsline {paragraph}{Polynomial regression}{5}}
\newlabel{eq:polynomialregression}{{3}{6}}
\@writefile{toc}{\contentsline {paragraph}{Logistic regression}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Rejection Mechanism for Classifiers}{6}}
\newlabel{sec:rejectionmechanism}{{3.6}{6}}
\@writefile{toc}{\contentsline {paragraph}{The ``one-versus-all'' method}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces ``one-versus-all'' rejection method. Unknown pattern passes through an array of specially prepared classifiers, one for each class. If each classifier says it is not native, it is rejected. }}{7}}
\newlabel{fig:rejection_version1}{{1}{7}}
\@writefile{toc}{\contentsline {paragraph}{The ``one-versus-one'' method}{7}}
\@writefile{toc}{\contentsline {paragraph}{The modified ``one-versus-one'' method}{7}}
\citation{LeCunCortesBurges}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  The ``one-versus-one'' rejection method. Each element passes through a\nobreakspace  {}collection of ``one-versus-one`` classifiers and has a\nobreakspace  {}counter summing up classification outcomes (we sum up how many times the pattern was classified to each native class). There are two rejection rules applied in this study that use the values stored in this counter array. }}{8}}
\newlabel{fig:rejection_version2}{{2}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7}Quality Evaluation}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiments}{8}}
\newlabel{sec:Experiments}{{4}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Presentation of Datasets}{8}}
\citation{Romanski}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Quality measures for classification with rejection.}}{9}}
\newlabel{tab:measures}{{1}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Samples of native patterns -- handwritten digits and foreign patterns -- handwritten Latin alphabet letters.}}{9}}
\newlabel{fig:nativeforeignpatterns}{{3}{9}}
\citation{NumPy,Scikit}
\citation{Scikit}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Experimental Settings}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Model Quality}{10}}
\newlabel{subsec:rejection_quality}{{4.3}{10}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Classification quality obtained with an ensemble of binary classifiers based on popular models like SVM, random forests (RF) and kNN for the test (hold-out) set of native patterns.}}{11}}
\newlabel{tab:results_classification_standard}{{2}{11}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Evaluation of classification quality for a\nobreakspace  {}classifying/rejecting model based on polynomial and logistic regression achieved on the test set. }}{11}}
\newlabel{tab:results_classification_regression}{{3}{11}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces  Quality of foreign patterns rejection/native patterns acceptance using proposed three methods based on popular algorithms: SVM, random forest and kNN. Results concern test set of native patterns mixed with the set of foreign elements (handwritten Latin alphabet letters).}}{11}}
\newlabel{tab:results_rejection_standard}{{4}{11}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Quality of foreign patterns rejection/native patterns acceptance for the three methods based on polynomial and logistic regression. Results concern test (hold-out set) of native patterns (handwritten digits) with the foreign set of handwritten letters.}}{11}}
\newlabel{tab:results_rejection_regression}{{5}{11}}
\bibcite{Altman1992}{1}
\bibcite{Breiman2001}{2}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{12}}
\newlabel{sec:Conclusion}{{5}{12}}
\bibcite{BreunigKriegelNgSander1999}{3}
\bibcite{Chawla2006}{4}
\bibcite{CortesVapnik1995}{5}
\bibcite{Ghoting2008}{6}
\bibcite{Grubbs1950}{7}
\bibcite{He2003}{8}
\bibcite{HempstalkFrankWitten2008}{9}
\bibcite{Kapoor2010}{10}
\bibcite{KimLee2006}{11}
\bibcite{KnorrNg1999}{12}
\bibcite{LeCunCortesBurges}{13}
\bibcite{Paalanen2006}{14}
\bibcite{PimentelCliftonTarassenko2014}{15}
\bibcite{Romanski}{16}
\bibcite{NumPy}{17}
\bibcite{Scikit}{18}
\bibcite{Song2007}{19}
\bibcite{Sun2004}{20}
\bibcite{Tukey1977}{21}
